# -*- coding: utf-8 -*-
"""
===================================
é»„é‡‘è¶‹åŠ¿åˆ†æå™¨ - åŸºäºé»„é‡‘å¸‚åœºç‰¹æ€§ä¼˜åŒ–
===================================

åŸºäºç”¨æˆ·äº¤æ˜“ç†å¿µï¼Œé’ˆå¯¹é»„é‡‘å¸‚åœºç‰¹æ€§è¿›è¡Œä¼˜åŒ–ï¼š
1. ä¸¥è¿›ç­–ç•¥ - ä¸è¿½é«˜ï¼Œè¿½æ±‚æ¯ç¬”äº¤æ˜“æˆåŠŸç‡
2. è¶‹åŠ¿äº¤æ˜“ - MA5>MA10>MA20 å¤šå¤´æ’åˆ—ï¼Œé¡ºåŠ¿è€Œä¸º
3. æ•ˆç‡ä¼˜å…ˆ - å…³æ³¨é»„é‡‘å¸‚åœºç‰¹æœ‰çš„é‡ä»·å…³ç³»
4. ä¹°ç‚¹åå¥½ - åœ¨ MA5/MA10 é™„è¿‘å›è¸©ä¹°å…¥

æŠ€æœ¯æ ‡å‡†ï¼š
- å¤šå¤´æ’åˆ—ï¼šMA5 > MA10 > MA20
- ä¹–ç¦»ç‡ï¼š(Close - MA5) / MA5 < 3%ï¼ˆä¸è¿½é«˜ï¼Œé»„é‡‘æ³¢åŠ¨ç›¸å¯¹è¾ƒå°ï¼‰
- é‡èƒ½å½¢æ€ï¼šç¼©é‡å›è°ƒä¼˜å…ˆï¼Œé»„é‡‘äº¤æ˜“é‡ç‰¹æ€§ä¸åŒ
"""

import logging
from dataclasses import dataclass, field
from typing import Optional, Dict, Any, List, Tuple
from enum import Enum

import pandas as pd
import numpy as np

from .stock_analyzer import StockTrendAnalyzer, TrendStatus, VolumeStatus, BuySignal, MACDStatus, RSIStatus, TrendAnalysisResult
from .search_service import get_search_service, SearchResponse
from .macro_data_provider import GoldMacroAnalyzer

logger = logging.getLogger(__name__)


class GoldTrendAnalyzer(StockTrendAnalyzer):
    """
    é»„é‡‘è¶‹åŠ¿åˆ†æå™¨

    åŸºäºè‚¡ç¥¨è¶‹åŠ¿åˆ†æå™¨æ‰©å±•ï¼Œé’ˆå¯¹é»„é‡‘å¸‚åœºç‰¹æ€§è¿›è¡Œä¼˜åŒ–ï¼š
    1. è¶‹åŠ¿åˆ¤æ–­ - MA5>MA10>MA20 å¤šå¤´æ’åˆ—
    2. ä¹–ç¦»ç‡æ£€æµ‹ - ä¸è¿½é«˜ï¼Œåç¦» MA5 è¶…è¿‡ 3% ä¸ä¹°ï¼ˆé»„é‡‘æ³¢åŠ¨ç›¸å¯¹è¾ƒå°ï¼‰
    3. é‡èƒ½åˆ†æ - åå¥½ç¼©é‡å›è°ƒï¼Œè°ƒæ•´é‡èƒ½åˆ¤æ–­é˜ˆå€¼
    4. ä¹°ç‚¹è¯†åˆ« - å›è¸© MA5/MA10 æ”¯æ’‘
    5. MACD æŒ‡æ ‡ - è¶‹åŠ¿ç¡®è®¤å’Œé‡‘å‰æ­»å‰ä¿¡å·
    6. RSI æŒ‡æ ‡ - è¶…ä¹°è¶…å–åˆ¤æ–­
    """
    
    # é»„é‡‘ç‰¹æœ‰çš„äº¤æ˜“å‚æ•°é…ç½®
    BIAS_THRESHOLD = 3.0        # ä¹–ç¦»ç‡é˜ˆå€¼ï¼ˆ%ï¼‰ï¼Œé»„é‡‘æ³¢åŠ¨ç›¸å¯¹è¾ƒå°ï¼Œè®¾ä¸º3%
    VOLUME_SHRINK_RATIO = 0.7   # ç¼©é‡åˆ¤æ–­é˜ˆå€¼ï¼ˆå½“æ—¥é‡/5æ—¥å‡é‡ï¼‰
    VOLUME_HEAVY_RATIO = 1.8    # æ”¾é‡åˆ¤æ–­é˜ˆå€¼ï¼Œé»„é‡‘äº¤æ˜“é‡ç‰¹æ€§ä¸åŒï¼Œè®¾ä¸º1.8
    MA_SUPPORT_TOLERANCE = 0.02  # MA æ”¯æ’‘åˆ¤æ–­å®¹å¿åº¦ï¼ˆ2%ï¼‰

    def __init__(self):
        """åˆå§‹åŒ–é»„é‡‘åˆ†æå™¨"""
        super().__init__()
        self.search_service = get_search_service()
        self.macro_analyzer = GoldMacroAnalyzer()
        logger.info("åˆå§‹åŒ–é»„é‡‘è¶‹åŠ¿åˆ†æå™¨")
    
    def _analyze_volume(self, df: pd.DataFrame, result: TrendAnalysisResult) -> None:
        """
        é’ˆå¯¹é»„é‡‘æœŸè´§ä¼˜åŒ–çš„é‡èƒ½åˆ†æ
        
        é»„é‡‘ç‰¹æœ‰çš„é‡èƒ½åˆ¤æ–­é€»è¾‘ï¼š
        1. è°ƒæ•´æ”¾é‡åˆ¤æ–­é˜ˆå€¼ä¸º1.8
        2. è€ƒè™‘é»„é‡‘ä½œä¸ºé¿é™©èµ„äº§çš„ç‰¹æ€§
        3. ä¼˜åŒ–é‡èƒ½è¶‹åŠ¿æè¿°ï¼Œæ·»åŠ é»„é‡‘ç‰¹æœ‰çš„åˆ†æè§†è§’
        """
        if len(df) < 5:
            return
        
        latest = df.iloc[-1]
        vol_5d_avg = df['volume'].iloc[-6:-1].mean()
        
        if vol_5d_avg > 0:
            result.volume_ratio_5d = float(latest['volume']) / vol_5d_avg
        
        # åˆ¤æ–­ä»·æ ¼å˜åŒ–
        prev_close = df.iloc[-2]['close']
        price_change = (latest['close'] - prev_close) / prev_close * 100
        
        # é»„é‡‘ç‰¹æœ‰çš„é‡èƒ½åˆ¤æ–­é€»è¾‘
        if result.volume_ratio_5d >= self.VOLUME_HEAVY_RATIO:
            if price_change > 0:
                result.volume_status = VolumeStatus.HEAVY_VOLUME_UP
                result.volume_trend = "æ”¾é‡ä¸Šæ¶¨ï¼Œå¤šå¤´åŠ›é‡å¼ºåŠ²ï¼ˆé»„é‡‘ï¼‰"
            else:
                result.volume_status = VolumeStatus.HEAVY_VOLUME_DOWN
                result.volume_trend = "æ”¾é‡ä¸‹è·Œï¼Œæ³¨æ„é£é™©ï¼ˆé»„é‡‘ï¼‰"
        elif result.volume_ratio_5d <= self.VOLUME_SHRINK_RATIO:
            if price_change > 0:
                result.volume_status = VolumeStatus.SHRINK_VOLUME_UP
                result.volume_trend = "ç¼©é‡ä¸Šæ¶¨ï¼Œä¸Šæ”»åŠ¨èƒ½ä¸è¶³ï¼ˆé»„é‡‘ï¼‰"
            else:
                result.volume_status = VolumeStatus.SHRINK_VOLUME_DOWN
                result.volume_trend = "ç¼©é‡å›è°ƒï¼Œæ´—ç›˜ç‰¹å¾æ˜æ˜¾ï¼ˆé»„é‡‘ï¼Œå¥½ï¼‰"
        else:
            result.volume_status = VolumeStatus.NORMAL
            result.volume_trend = "é‡èƒ½æ­£å¸¸ï¼ˆé»„é‡‘ï¼‰"
    
    def _analyze_trend(self, df: pd.DataFrame, result: TrendAnalysisResult) -> None:
        """
        åˆ†æé»„é‡‘è¶‹åŠ¿çŠ¶æ€
        
        åŸºäºè‚¡ç¥¨è¶‹åŠ¿åˆ†æé€»è¾‘ï¼Œé’ˆå¯¹é»„é‡‘ç‰¹æ€§è¿›è¡Œä¼˜åŒ–ï¼š
        1. é»„é‡‘è¶‹åŠ¿å½¢æˆå’ŒæŒç»­æ—¶é—´ä¸åŒ
        2. é»„é‡‘ä½œä¸ºé¿é™©èµ„äº§çš„ç‰¹æ€§
        """
        super()._analyze_trend(df, result)
        
        # æ·»åŠ é»„é‡‘ç‰¹æœ‰çš„è¶‹åŠ¿åˆ†æé€»è¾‘
        if result.trend_status in [TrendStatus.STRONG_BULL, TrendStatus.BULL]:
            # é»„é‡‘å¤šå¤´è¶‹åŠ¿å¯èƒ½æ›´æŒä¹…
            result.ma_alignment += "ï¼ˆé»„é‡‘å¤šå¤´è¶‹åŠ¿å¯èƒ½æ›´æŒä¹…ï¼‰"
        elif result.trend_status in [TrendStatus.STRONG_BEAR, TrendStatus.BEAR]:
            # é»„é‡‘ç©ºå¤´è¶‹åŠ¿å¯èƒ½ç›¸å¯¹çŸ­æš‚ï¼Œå¾€å¾€æ˜¯å›è°ƒ
            result.ma_alignment += "ï¼ˆé»„é‡‘ç©ºå¤´è¶‹åŠ¿å¯èƒ½ç›¸å¯¹çŸ­æš‚ï¼Œå…³æ³¨åå¼¹ï¼‰"
    
    def _generate_signal(self, result: TrendAnalysisResult) -> None:
        """
        ç”Ÿæˆé»„é‡‘ç‰¹æœ‰çš„ä¹°å…¥ä¿¡å·
        
        åŸºäºè‚¡ç¥¨ä¿¡å·ç”Ÿæˆé€»è¾‘ï¼Œé’ˆå¯¹é»„é‡‘ç‰¹æ€§è¿›è¡Œä¼˜åŒ–ï¼š
        1. è€ƒè™‘é»„é‡‘ä½œä¸ºé¿é™©èµ„äº§çš„ç‰¹æ€§
        2. é»„é‡‘ä»·æ ¼æ³¢åŠ¨ç›¸å¯¹è¾ƒå°ï¼Œä¿¡å·é˜ˆå€¼è°ƒæ•´
        """
        super()._generate_signal(result)
        
        # æ·»åŠ é»„é‡‘ç‰¹æœ‰çš„ä¿¡å·åˆ†æ
        if result.buy_signal in [BuySignal.STRONG_BUY, BuySignal.BUY]:
            # é»„é‡‘ä¹°å…¥ä¿¡å·å¯èƒ½æ›´å¯é 
            result.signal_reasons.append("âœ… é»„é‡‘ä¹°å…¥ä¿¡å·ï¼Œé¿é™©èµ„äº§ç‰¹æ€§å¢å¼ºå¯é æ€§")
        elif result.buy_signal in [BuySignal.SELL, BuySignal.STRONG_SELL]:
            # é»„é‡‘å–å‡ºä¿¡å·å¯èƒ½éœ€è¦æ›´è°¨æ…åˆ¤æ–­
            result.risk_factors.append("âš ï¸ é»„é‡‘å–å‡ºä¿¡å·ï¼Œéœ€è€ƒè™‘é¿é™©éœ€æ±‚å¯¹ä»·æ ¼çš„æ”¯æ’‘")
    
    def _analyze_macro_factors(self, macro_news: dict) -> dict:
        """
        åˆ†æå®è§‚å› ç´ å¯¹é»„é‡‘çš„å½±å“
        
        Args:
            macro_news: å®è§‚æ–°é—»æœç´¢ç»“æœ
            
        Returns:
            åŒ…å«å®è§‚åˆ†æç»“æœçš„å­—å…¸
        """
        factors = {}
        total_score = 50
        
        # åˆ©å¥½å…³é”®è¯
        bullish_keywords = ['åŠ æ¯', 'é€šèƒ€', 'åœ°ç¼˜æ”¿æ²»', 'é¿é™©', 'å¤®è¡Œè´­é‡‘', 'ä¸ç¡®å®šæ€§']
        # åˆ©ç©ºå…³é”®è¯
        bearish_keywords = ['é™æ¯', 'ç»æµå¼ºåŠ²', 'ç¾å…ƒèµ°å¼º', 'é€šèƒ€ç¼“è§£']
        
        for category, response in macro_news.items():
            if not response.success or not response.results:
                continue
            
            category_score = 50
            bullish_count = 0
            bearish_count = 0
            
            for result in response.results:
                content = f"{result.title} {result.snippet}"
                # ç»Ÿè®¡å…³é”®è¯
                for kw in bullish_keywords:
                    if kw in content:
                        bullish_count += 1
                for kw in bearish_keywords:
                    if kw in content:
                        bearish_count += 1
            
            # è®¡ç®—å¾—åˆ†
            if bullish_count > bearish_count:
                category_score = min(80, 50 + (bullish_count - bearish_count) * 10)
            elif bearish_count > bullish_count:
                category_score = max(20, 50 - (bearish_count - bullish_count) * 10)
            
            factors[category] = {
                'score': category_score,
                'bullish_count': bullish_count,
                'bearish_count': bearish_count
            }
            total_score += (category_score - 50) * 0.1
        
        total_score = max(0, min(100, total_score))
        
        return {
            'total_score': round(total_score),
            'factors': factors,
            'timestamp': pd.Timestamp.now().isoformat()
        }
    
    def analyze_with_macro(self, df: pd.DataFrame, code: str) -> TrendAnalysisResult:
        """
        å¸¦å®è§‚å› ç´ çš„é»„é‡‘åˆ†æ
        
        Args:
            df: åŒ…å« OHLCV æ•°æ®çš„ DataFrame
            code: é»„é‡‘ä»£ç 
            
        Returns:
            TrendAnalysisResult åˆ†æç»“æœ
        """
        # 1. æ‰§è¡ŒåŸºç¡€æŠ€æœ¯åˆ†æ
        result = self.analyze(df, code)
        
        # 2. è·å–å®è§‚æ–°é—»
        macro_news_score = 50
        try:
            if self.search_service and self.search_service.is_available:
                logger.info(f"æœç´¢é»„é‡‘å®è§‚å› ç´ æ–°é—»")
                macro_news = self.search_service.search_gold_macro_news(max_results=3)
                
                if macro_news:
                    # åˆ†ææ–°é—»å®è§‚å› ç´ 
                    news_analysis = self._analyze_macro_factors(macro_news)
                    macro_news_score = news_analysis['total_score']
                    result.macro_news = macro_news
                    logger.info(f"æ–°é—»å®è§‚å› ç´ åˆ†æå®Œæˆï¼Œæ€»è¯„åˆ†: {macro_news_score}")
                else:
                    logger.info("æœªè·å–åˆ°å®è§‚æ–°é—»æ•°æ®")
            else:
                logger.info("æœç´¢æœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡æ–°é—»å®è§‚å› ç´ åˆ†æ")
        except Exception as e:
            logger.warning(f"è·å–å®è§‚æ–°é—»å¤±è´¥: {e}")
        
        # 3. è·å–ç»“æ„åŒ–å®è§‚æ•°æ®
        macro_data_score = 50
        try:
            logger.info(f"è·å–é»„é‡‘å®è§‚æ•°æ®")
            macro_data = self.macro_analyzer.get_macro_score()
            
            if macro_data:
                macro_data_score = macro_data['total_score']
                result.macro_score = macro_data_score
                result.macro_factors = macro_data['factors']
                result.macro_summary = macro_data['summary']
                result.macro_timestamp = macro_data['timestamp']
                logger.info(f"ç»“æ„åŒ–å®è§‚æ•°æ®åˆ†æå®Œæˆï¼Œæ€»è¯„åˆ†: {macro_data_score}")
            else:
                logger.info("æœªè·å–åˆ°ç»“æ„åŒ–å®è§‚æ•°æ®")
        except Exception as e:
            logger.warning(f"è·å–ç»“æ„åŒ–å®è§‚æ•°æ®å¤±è´¥: {e}")
        
        # 4. è®¡ç®—ç»¼åˆå®è§‚è¯„åˆ†
        # æ–°é—»è¯„åˆ†æƒé‡ 30%ï¼Œç»“æ„åŒ–æ•°æ®è¯„åˆ†æƒé‡ 70%
        total_macro_score = int(macro_news_score * 0.3 + macro_data_score * 0.7)
        total_macro_score = max(0, min(100, total_macro_score))
        
        # ä¿å­˜åŸå§‹æŠ€æœ¯è¯„åˆ†å’Œå„é¡¹å®è§‚è¯„åˆ†ï¼ˆç”¨äºæŠ¥å‘Šå±•ç¤ºï¼‰
        original_technical_score = result.signal_score  # ä¿å­˜æŠ€æœ¯è¯„åˆ†
        result.technical_score = original_technical_score  # æŠ€æœ¯è¯„åˆ†ï¼ˆè°ƒæ•´å‰ï¼‰
        result.macro_news_score = macro_news_score  # æ–°é—»è¯„åˆ†
        result.macro_data_score = macro_data_score  # æ•°æ®è¯„åˆ†
        result.total_macro_score = total_macro_score  # ç»¼åˆå®è§‚è¯„åˆ†
        
        # 5. è°ƒæ•´ç»¼åˆè¯„åˆ†
        # æŠ€æœ¯è¯„åˆ†æƒé‡ 60%ï¼Œå®è§‚è¯„åˆ†æƒé‡ 40%
        result.signal_score = int(original_technical_score * 0.6 + total_macro_score * 0.4)
        result.signal_score = max(0, min(100, result.signal_score))
        
        logger.info(f"æŠ€æœ¯è¯„åˆ†: {original_technical_score}, æ–°é—»è¯„åˆ†: {macro_news_score}, "
                   f"æ•°æ®è¯„åˆ†: {macro_data_score}, ç»¼åˆå®è§‚è¯„åˆ†: {total_macro_score}, "
                   f"æœ€ç»ˆä¿¡å·è¯„åˆ†: {result.signal_score}")
        
        return result
    
    def format_analysis(self, result: TrendAnalysisResult) -> str:
        """
        æ ¼å¼åŒ–é»„é‡‘åˆ†æç»“æœä¸ºæ–‡æœ¬
        
        Args:
            result: åˆ†æç»“æœ

        Returns:
            æ ¼å¼åŒ–çš„åˆ†ææ–‡æœ¬
        """
        lines = [
            f"=== {result.code} é»„é‡‘è¶‹åŠ¿åˆ†æ ===",
            f"",
            f"ğŸ“Š è¶‹åŠ¿åˆ¤æ–­: {result.trend_status.value}",
            f"   å‡çº¿æ’åˆ—: {result.ma_alignment}",
            f"   è¶‹åŠ¿å¼ºåº¦: {result.trend_strength}/100",
            f"",
            f"ğŸ“ˆ å‡çº¿æ•°æ®:",
            f"   ç°ä»·: {result.current_price:.2f}",
            f"   MA5:  {result.ma5:.2f} (ä¹–ç¦» {result.bias_ma5:+.2f}%)",
            f"   MA10: {result.ma10:.2f} (ä¹–ç¦» {result.bias_ma10:+.2f}%)",
            f"   MA20: {result.ma20:.2f} (ä¹–ç¦» {result.bias_ma20:+.2f}%)",
            f"",
            f"ğŸ“Š é‡èƒ½åˆ†æ: {result.volume_status.value}",
            f"   é‡æ¯”(vs5æ—¥): {result.volume_ratio_5d:.2f}",
            f"   é‡èƒ½è¶‹åŠ¿: {result.volume_trend}",
            f"",
            f"ğŸ“ˆ MACDæŒ‡æ ‡: {result.macd_status.value}",
            f"   DIF: {result.macd_dif:.4f}",
            f"   DEA: {result.macd_dea:.4f}",
            f"   MACD: {result.macd_bar:.4f}",
            f"   ä¿¡å·: {result.macd_signal}",
            f"",
            f"ğŸ“Š RSIæŒ‡æ ‡: {result.rsi_status.value}",
            f"   RSI(6): {result.rsi_6:.1f}",
            f"   RSI(12): {result.rsi_12:.1f}",
            f"   RSI(24): {result.rsi_24:.1f}",
            f"   ä¿¡å·: {result.rsi_signal}",
            f"",
            f"ğŸ¯ æ“ä½œå»ºè®®: {result.buy_signal.value}",
            f"   ç»¼åˆè¯„åˆ†: {result.signal_score}/100",
        ]

        if result.signal_reasons:
            lines.append(f"")
            lines.append(f"âœ… ä¹°å…¥ç†ç”±:")
            for reason in result.signal_reasons:
                lines.append(f"   {reason}")

        if result.risk_factors:
            lines.append(f"")
            lines.append(f"âš ï¸ é£é™©å› ç´ :")
            for risk in result.risk_factors:
                lines.append(f"   {risk}")

        # æ·»åŠ é»„é‡‘ç‰¹æœ‰çš„åˆ†ææç¤º
        lines.append(f"")
        lines.append(f"ğŸ’¡ é»„é‡‘å¸‚åœºæç¤º:")
        lines.append(f"   - é»„é‡‘ä½œä¸ºé¿é™©èµ„äº§ï¼Œåœ¨å¸‚åœºä¸ç¡®å®šæ€§å¢åŠ æ—¶å¾€å¾€è¡¨ç°å¼ºåŠ¿")
        lines.append(f"   - é»„é‡‘ä»·æ ¼å—å…¨çƒå®è§‚ç»æµã€åœ°ç¼˜æ”¿æ²»ç­‰å› ç´ å½±å“è¾ƒå¤§")
        lines.append(f"   - é»„é‡‘è¶‹åŠ¿ä¸€æ—¦å½¢æˆï¼Œå¾€å¾€æŒç»­æ—¶é—´è¾ƒé•¿")

        # æ·»åŠ å®è§‚å› ç´ åˆ†æ
        if hasattr(result, 'macro_score') and result.macro_score is not None:
            lines.append(f"")
            lines.append(f"ğŸŒ å®è§‚å› ç´ åˆ†æ:")
            
            # æ˜¾ç¤ºè¯„åˆ†è¯¦æƒ…ï¼ˆå¦‚æœæœ‰ï¼‰
            if hasattr(result, 'technical_score'):
                lines.append(f"   è¯„åˆ†è¯¦æƒ…:")
                lines.append(f"   - æŠ€æœ¯è¯„åˆ†: {result.technical_score}/100 (æƒé‡60%)")
                lines.append(f"   - å®è§‚è¯„åˆ†: {result.total_macro_score}/100 (æƒé‡40%)")
                if hasattr(result, 'macro_news_score'):
                    lines.append(f"     - æ–°é—»è¯„åˆ†: {result.macro_news_score}/100 (æƒé‡30%)")
                if hasattr(result, 'macro_data_score'):
                    lines.append(f"     - æ•°æ®è¯„åˆ†: {result.macro_data_score}/100 (æƒé‡70%)")
                lines.append(f"")
            
            lines.append(f"   ç»¼åˆè¯„åˆ†: {result.macro_score}/100")
            
            if hasattr(result, 'macro_summary') and result.macro_summary:
                lines.append(f"   åˆ†ææ€»ç»“: {result.macro_summary}")
            
            if hasattr(result, 'macro_factors') and result.macro_factors:
                lines.append(f"   å…³é”®å› ç´ :")
                for factor_name, factor_data in result.macro_factors.items():
                    score = factor_data['score']
                    value = factor_data.get('value', 'N/A')
                    change = factor_data.get('change', '')
                    change_str = f" (å˜åŒ–{change}%)" if change else ""
                    emoji = "ğŸ“ˆ" if score > 60 else "ğŸ“‰" if score < 40 else "â¡ï¸"
                    lines.append(f"   {emoji} {factor_name}: {value}{change_str} ({score}/100)")
            
            if hasattr(result, 'macro_news') and result.macro_news:
                lines.append(f"")
                lines.append(f"ğŸ“° å®è§‚æ–°é—»æ‘˜è¦:")
                news_count = 0
                for category, response in result.macro_news.items():
                    if response.success and response.results:
                        for i, news in enumerate(response.results[:1]):  # æ¯ä¸ªç±»åˆ«åªæ˜¾ç¤º1æ¡æ–°é—»
                            if news_count >= 3:
                                break
                            lines.append(f"   â€¢ {news.title[:80]}")
                            news_count += 1
                        if news_count >= 3:
                            break
            
            if hasattr(result, 'macro_timestamp'):
                lines.append(f"")
                lines.append(f"   ğŸ•’ æ•°æ®æ—¶é—´: {result.macro_timestamp[:19]}")

        return "\n".join(lines)


def analyze_gold(df: pd.DataFrame, code: str, include_macro: bool = True) -> TrendAnalysisResult:
    """
    ä¾¿æ·å‡½æ•°ï¼šåˆ†æé»„é‡‘æ•°æ®
    
    Args:
        df: åŒ…å« OHLCV æ•°æ®çš„ DataFrame
        code: é»„é‡‘ä»£ç 
        include_macro: æ˜¯å¦åŒ…å«å®è§‚å› ç´ åˆ†æ
        
    Returns:
        TrendAnalysisResult åˆ†æç»“æœ
    """
    analyzer = GoldTrendAnalyzer()
    if include_macro:
        return analyzer.analyze_with_macro(df, code)
    else:
        return analyzer.analyze(df, code)


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    logging.basicConfig(level=logging.INFO)
    
    # æ¨¡æ‹Ÿé»„é‡‘æ•°æ®æµ‹è¯•
    import numpy as np
    
    dates = pd.date_range(start='2025-01-01', periods=60, freq='D')
    np.random.seed(42)
    
    # æ¨¡æ‹Ÿé»„é‡‘ä»·æ ¼æ•°æ®ï¼ˆæ³¢åŠ¨ç›¸å¯¹è¾ƒå°ï¼‰
    base_price = 2000.0
    prices = [base_price]
    for i in range(59):
        change = np.random.randn() * 0.01 + 0.002  # é»„é‡‘æ³¢åŠ¨ç›¸å¯¹è¾ƒå°
        prices.append(prices[-1] * (1 + change))
    
    df = pd.DataFrame({
        'date': dates,
        'open': prices,
        'high': [p * (1 + np.random.uniform(0, 0.01)) for p in prices],
        'low': [p * (1 - np.random.uniform(0, 0.01)) for p in prices],
        'close': prices,
        'volume': [np.random.randint(100000, 500000) for _ in prices],  # é»„é‡‘äº¤æ˜“é‡ç‰¹æ€§
    })
    
    analyzer = GoldTrendAnalyzer()
    result = analyzer.analyze(df, 'GC=F')
    print(analyzer.format_analysis(result))
